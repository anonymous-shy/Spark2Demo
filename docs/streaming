Spark Streaming
集群节点上总共拥有的CPU core :
首先,一定要大于Spark Streaming App 的Receiver数量,因为一个Receiver独占一个CPU core.
其次,在spark-submit中,给App分配的CPU core的数量,肯定是 <= 集群的CPU core的数量,但是必须 > App中Receiver数量.

在集群中运行的Spark Streaming App中的executor是一个长时间运行的任务,因此它会独占分配给App的CPU core.
并且每个executor分配的core,必须 > 1.
这样才能保证分配到executor上运行的DStream两条线程并行,一条运行Receiver,接收数据.一条处理数据.

Kafka数据源
1.基于Receiver方式:
    Receiver是使用Kafka High level Consumer API实现的.
    Receiver从kafka中获取数据都存在Spark Executor的内存中,然后Streaming启动job去处理数据.
    然而,在默认配置下,这种方式会因为底层的失败而导致丢失数据,
    如果启用高可用机制,让数据零丢失,就必须开启streaming的预写日志机制(Write Ahead Log WAL).
    该机制会同步地将接收到的kafka数据写入分布式文件系统(比如hdfs)上的预写日志中.
    所以,即使底层节点出现了失败,也可以使用预写日志中的数据进行恢复.
2.基于Direct方式: 可以确保
